{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yv3IDvrobU37"
   },
   "source": [
    "# Portfolio Optimization using Deep Reinforcement Learning\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4kHCfEiTA80V"
   },
   "source": [
    "## 8.0 Deep Reinforcement Learning Portfolios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12v1i0jVkg48"
   },
   "source": [
    "### 8.1 Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ntfTb0e2bU4C",
    "outputId": "d268ef40-e425-4671-f1ec-e9e5d6b65659",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "from pypfopt.efficient_frontier import efficient_frontier\n",
    "from pypfopt.efficient_frontier.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import efficient_frontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import finrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyfolio/pos.py:25: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Imports from the FinRL Library\n",
    "\n",
    "from finrl import config\n",
    "from backtest import BackTestStats, BaselineStats, BackTestPlot, backtest_strat, baseline_strat\n",
    "from backtest import backtest_strat, baseline_strat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r train_df\n",
    "%store -r test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_indicator_list = ['f01','f02','f03','f04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>cov_list</th>\n",
       "      <th>f01</th>\n",
       "      <th>f02</th>\n",
       "      <th>f03</th>\n",
       "      <th>f04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-13</td>\n",
       "      <td>ASIANPAINT.NS</td>\n",
       "      <td>91.699997</td>\n",
       "      <td>88.500000</td>\n",
       "      <td>91.235001</td>\n",
       "      <td>88.500000</td>\n",
       "      <td>65800</td>\n",
       "      <td>[[0.0005821350723573744, 0.0001385649017777150...</td>\n",
       "      <td>0.646335</td>\n",
       "      <td>0.708096</td>\n",
       "      <td>0.085455</td>\n",
       "      <td>2.997396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-13</td>\n",
       "      <td>CIPLA.NS</td>\n",
       "      <td>189.649994</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>185.350006</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>901712</td>\n",
       "      <td>[[0.0005821350723573744, 0.0001385649017777150...</td>\n",
       "      <td>0.646335</td>\n",
       "      <td>0.708096</td>\n",
       "      <td>0.085455</td>\n",
       "      <td>2.997396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-13</td>\n",
       "      <td>DRREDDY.NS</td>\n",
       "      <td>478.000000</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>452.750000</td>\n",
       "      <td>465.750000</td>\n",
       "      <td>544994</td>\n",
       "      <td>[[0.0005821350723573744, 0.0001385649017777150...</td>\n",
       "      <td>0.646335</td>\n",
       "      <td>0.708096</td>\n",
       "      <td>0.085455</td>\n",
       "      <td>2.997396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-13</td>\n",
       "      <td>GAIL.NS</td>\n",
       "      <td>39.375019</td>\n",
       "      <td>37.875019</td>\n",
       "      <td>38.756268</td>\n",
       "      <td>38.606270</td>\n",
       "      <td>9334277</td>\n",
       "      <td>[[0.0005821350723573744, 0.0001385649017777150...</td>\n",
       "      <td>0.646335</td>\n",
       "      <td>0.708096</td>\n",
       "      <td>0.085455</td>\n",
       "      <td>2.997396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-13</td>\n",
       "      <td>GRASIM.NS</td>\n",
       "      <td>209.852203</td>\n",
       "      <td>202.908554</td>\n",
       "      <td>204.891357</td>\n",
       "      <td>205.570282</td>\n",
       "      <td>1994905</td>\n",
       "      <td>[[0.0005821350723573744, 0.0001385649017777150...</td>\n",
       "      <td>0.646335</td>\n",
       "      <td>0.708096</td>\n",
       "      <td>0.085455</td>\n",
       "      <td>2.997396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date            tic       close        high         low        open  \\\n",
       "0  2009-01-13  ASIANPAINT.NS   91.699997   88.500000   91.235001   88.500000   \n",
       "0  2009-01-13       CIPLA.NS  189.649994  184.000000  185.350006  185.000000   \n",
       "0  2009-01-13     DRREDDY.NS  478.000000  448.000000  452.750000  465.750000   \n",
       "0  2009-01-13        GAIL.NS   39.375019   37.875019   38.756268   38.606270   \n",
       "0  2009-01-13      GRASIM.NS  209.852203  202.908554  204.891357  205.570282   \n",
       "\n",
       "    volume                                           cov_list       f01  \\\n",
       "0    65800  [[0.0005821350723573744, 0.0001385649017777150...  0.646335   \n",
       "0   901712  [[0.0005821350723573744, 0.0001385649017777150...  0.646335   \n",
       "0   544994  [[0.0005821350723573744, 0.0001385649017777150...  0.646335   \n",
       "0  9334277  [[0.0005821350723573744, 0.0001385649017777150...  0.646335   \n",
       "0  1994905  [[0.0005821350723573744, 0.0001385649017777150...  0.646335   \n",
       "\n",
       "        f02       f03       f04  \n",
       "0  0.708096  0.085455  2.997396  \n",
       "0  0.708096  0.085455  2.997396  \n",
       "0  0.708096  0.085455  2.997396  \n",
       "0  0.708096  0.085455  2.997396  \n",
       "0  0.708096  0.085455  2.997396  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59660, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxQTNjpblAMN"
   },
   "source": [
    "### 8.4 Implement DRL Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finrl.agents.elegantrl.models import DRLAgent\n",
    "from finrl.meta.env_portfolio_allocation.env_portfolio import StockPortfolioEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import env_portfolio\n",
    "from env_portfolio import StockPortfolioEnv\n",
    "\n",
    "import train_models\n",
    "from train_models import DRLAgents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MzD06X0CbU43",
    "outputId": "0ebe2d36-2f98-4c07-b69d-b4cebfd09193"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 20, State Space: 20\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train_df.tic.unique())\n",
    "state_space = stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_initial = [1/stock_dimension]*stock_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "jyg0_ZuVEVQ5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 500, \n",
    "    \"initial_amount\": 1000000, \n",
    "    \"transaction_cost_pct\": 0.001, \n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": tech_indicator_list, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 0,\n",
    "    'initial_weights': [1/stock_dimension]*stock_dimension\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_train_gym = StockPortfolioEnv(df = train_df, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HTlOf8SJGdkl",
    "outputId": "1a3da41c-194d-4b94-ba52-713333b58e1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdPe8uzflbXe"
   },
   "source": [
    "#### 8.4.1 Model 1: A2C: Advantage Actor-Critic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import env_portfolio\n",
    "from env_portfolio import StockPortfolioEnv\n",
    "\n",
    "import train_models\n",
    "from train_models import DRLAgents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>cov_list</th>\n",
       "      <th>f01</th>\n",
       "      <th>f02</th>\n",
       "      <th>f03</th>\n",
       "      <th>f04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-13</td>\n",
       "      <td>ASIANPAINT.NS</td>\n",
       "      <td>91.699997</td>\n",
       "      <td>88.500000</td>\n",
       "      <td>91.235001</td>\n",
       "      <td>88.500000</td>\n",
       "      <td>65800</td>\n",
       "      <td>[[0.0005821350723573744, 0.0001385649017777150...</td>\n",
       "      <td>0.646335</td>\n",
       "      <td>0.708096</td>\n",
       "      <td>0.085455</td>\n",
       "      <td>2.997396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-13</td>\n",
       "      <td>CIPLA.NS</td>\n",
       "      <td>189.649994</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>185.350006</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>901712</td>\n",
       "      <td>[[0.0005821350723573744, 0.0001385649017777150...</td>\n",
       "      <td>0.646335</td>\n",
       "      <td>0.708096</td>\n",
       "      <td>0.085455</td>\n",
       "      <td>2.997396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-13</td>\n",
       "      <td>DRREDDY.NS</td>\n",
       "      <td>478.000000</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>452.750000</td>\n",
       "      <td>465.750000</td>\n",
       "      <td>544994</td>\n",
       "      <td>[[0.0005821350723573744, 0.0001385649017777150...</td>\n",
       "      <td>0.646335</td>\n",
       "      <td>0.708096</td>\n",
       "      <td>0.085455</td>\n",
       "      <td>2.997396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-13</td>\n",
       "      <td>GAIL.NS</td>\n",
       "      <td>39.375019</td>\n",
       "      <td>37.875019</td>\n",
       "      <td>38.756268</td>\n",
       "      <td>38.606270</td>\n",
       "      <td>9334277</td>\n",
       "      <td>[[0.0005821350723573744, 0.0001385649017777150...</td>\n",
       "      <td>0.646335</td>\n",
       "      <td>0.708096</td>\n",
       "      <td>0.085455</td>\n",
       "      <td>2.997396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-13</td>\n",
       "      <td>GRASIM.NS</td>\n",
       "      <td>209.852203</td>\n",
       "      <td>202.908554</td>\n",
       "      <td>204.891357</td>\n",
       "      <td>205.570282</td>\n",
       "      <td>1994905</td>\n",
       "      <td>[[0.0005821350723573744, 0.0001385649017777150...</td>\n",
       "      <td>0.646335</td>\n",
       "      <td>0.708096</td>\n",
       "      <td>0.085455</td>\n",
       "      <td>2.997396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date            tic       close        high         low        open  \\\n",
       "0  2009-01-13  ASIANPAINT.NS   91.699997   88.500000   91.235001   88.500000   \n",
       "0  2009-01-13       CIPLA.NS  189.649994  184.000000  185.350006  185.000000   \n",
       "0  2009-01-13     DRREDDY.NS  478.000000  448.000000  452.750000  465.750000   \n",
       "0  2009-01-13        GAIL.NS   39.375019   37.875019   38.756268   38.606270   \n",
       "0  2009-01-13      GRASIM.NS  209.852203  202.908554  204.891357  205.570282   \n",
       "\n",
       "    volume                                           cov_list       f01  \\\n",
       "0    65800  [[0.0005821350723573744, 0.0001385649017777150...  0.646335   \n",
       "0   901712  [[0.0005821350723573744, 0.0001385649017777150...  0.646335   \n",
       "0   544994  [[0.0005821350723573744, 0.0001385649017777150...  0.646335   \n",
       "0  9334277  [[0.0005821350723573744, 0.0001385649017777150...  0.646335   \n",
       "0  1994905  [[0.0005821350723573744, 0.0001385649017777150...  0.646335   \n",
       "\n",
       "        f02       f03       f04  \n",
       "0  0.708096  0.085455  2.997396  \n",
       "0  0.708096  0.085455  2.997396  \n",
       "0  0.708096  0.085455  2.997396  \n",
       "0  0.708096  0.085455  2.997396  \n",
       "0  0.708096  0.085455  2.997396  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_excel('train.xlsx', sheet_name=\"train_df\", index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_models import DRLAgents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t1tORf1fIcQ2",
    "outputId": "781e90cf-175e-4f85-9667-c60a95d6a1dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0002}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "agent = DRLAgents(env=env_train)\n",
    "\n",
    "A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n",
    "model_a2c = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DazEdrMpIdyz",
    "outputId": "387049f6-f0b9-4010-b12d-b4e27c182cc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to tensorboard_log/a2c/a2c_104\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 20 and the array at index 1 has size 19",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trained_a2c \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_a2c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ma2c\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Capstone Options/Capstone-Indian data/train_models.py:117\u001b[0m, in \u001b[0;36mDRLAgents.train_model\u001b[0;34m(self, model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, tb_log_name, total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m):\n\u001b[0;32m--> 117\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stable_baselines3/a2c/a2c.py:201\u001b[0m, in \u001b[0;36mA2C.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfA2C,\n\u001b[1;32m    194\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    200\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfA2C:\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:277\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 277\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:194\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;66;03m# Otherwise, clip the actions to avoid out of bound error\u001b[39;00m\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;66;03m# as we are sampling from an unbounded Gaussian distribution\u001b[39;00m\n\u001b[1;32m    192\u001b[0m         clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[0;32m--> 194\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[0;32m---> 58\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/shimmy/openai_gym_compatibility.py:251\u001b[0m, in \u001b[0;36mGymV21CompatibilityV0.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action: ActType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[Any, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m]:\n\u001b[1;32m    243\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m        (observation, reward, terminated, truncated, info)\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m     obs, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgym_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender()\n",
      "File \u001b[0;32m~/Documents/Capstone Options/Capstone-Indian data/env_portfolio.py:187\u001b[0m, in \u001b[0;36mStockPortfolioEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mday,:]\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcov_list\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m  \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcovs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtech\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtech\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtech_indicator_list\u001b[49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m#print(self.state)\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# calcualte portfolio return\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# individual stocks' return * weight\u001b[39;00m\n\u001b[1;32m    191\u001b[0m portfolio_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mclose\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;241m/\u001b[39m last_day_memory\u001b[38;5;241m.\u001b[39mclose\u001b[38;5;241m.\u001b[39mvalues)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mweights)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/lib/function_base.py:5618\u001b[0m, in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   5616\u001b[0m     values \u001b[38;5;241m=\u001b[39m ravel(values)\n\u001b[1;32m   5617\u001b[0m     axis \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 5618\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 20 and the array at index 1 has size 19"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                                tb_log_name='a2c',\n",
    "                                total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.4.2 Model 2: PPO : Proximal Policy Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kVXta7jVKMhV",
    "outputId": "4cb82ab6-914d-4d2b-a4ee-e47c8557dad3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.005, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgents(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.005,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z5XlUIszKUGx",
    "outputId": "3989711a-cbed-4649-e71c-566d52917478"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to tensorboard_log/ppo/ppo_6\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 3629 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1000000.0\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 2761     |\n",
      "|    iterations           | 2        |\n",
      "|    time_elapsed         | 1        |\n",
      "|    total_timesteps      | 4096     |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -28.4    |\n",
      "|    explained_variance   | 0        |\n",
      "|    learning_rate        | 0.0001   |\n",
      "|    loss                 | 1.41e+14 |\n",
      "|    n_updates            | 10       |\n",
      "|    policy_gradient_loss | 9.55e-09 |\n",
      "|    std                  | 1        |\n",
      "|    value_loss           | 2.79e+14 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1000000.0\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 2560      |\n",
      "|    iterations           | 3         |\n",
      "|    time_elapsed         | 2         |\n",
      "|    total_timesteps      | 6144      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.38e+14  |\n",
      "|    n_updates            | 20        |\n",
      "|    policy_gradient_loss | -5.98e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.76e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 2554      |\n",
      "|    iterations           | 4         |\n",
      "|    time_elapsed         | 3         |\n",
      "|    total_timesteps      | 8192      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.37e+14  |\n",
      "|    n_updates            | 30        |\n",
      "|    policy_gradient_loss | -3.32e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.76e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1000000.0\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 2515      |\n",
      "|    iterations           | 5         |\n",
      "|    time_elapsed         | 4         |\n",
      "|    total_timesteps      | 10240     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 3.58e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.4e+14   |\n",
      "|    n_updates            | 40        |\n",
      "|    policy_gradient_loss | -5.83e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.79e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1000000.0\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 2474      |\n",
      "|    iterations           | 6         |\n",
      "|    time_elapsed         | 4         |\n",
      "|    total_timesteps      | 12288     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.39e+14  |\n",
      "|    n_updates            | 50        |\n",
      "|    policy_gradient_loss | -9.15e-08 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.76e+14  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 2497     |\n",
      "|    iterations           | 7        |\n",
      "|    time_elapsed         | 5        |\n",
      "|    total_timesteps      | 14336    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -28.4    |\n",
      "|    explained_variance   | 5.96e-08 |\n",
      "|    learning_rate        | 0.0001   |\n",
      "|    loss                 | 1.35e+14 |\n",
      "|    n_updates            | 60       |\n",
      "|    policy_gradient_loss | -3.1e-07 |\n",
      "|    std                  | 1        |\n",
      "|    value_loss           | 2.76e+14 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1000000.0\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 2484      |\n",
      "|    iterations           | 8         |\n",
      "|    time_elapsed         | 6         |\n",
      "|    total_timesteps      | 16384     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.41e+14  |\n",
      "|    n_updates            | 70        |\n",
      "|    policy_gradient_loss | 8.6e-07   |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.79e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1000000.0\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 2455      |\n",
      "|    iterations           | 9         |\n",
      "|    time_elapsed         | 7         |\n",
      "|    total_timesteps      | 18432     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.36e+14  |\n",
      "|    n_updates            | 80        |\n",
      "|    policy_gradient_loss | -1.45e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.76e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 2460      |\n",
      "|    iterations           | 10        |\n",
      "|    time_elapsed         | 8         |\n",
      "|    total_timesteps      | 20480     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.39e+14  |\n",
      "|    n_updates            | 90        |\n",
      "|    policy_gradient_loss | -4.35e-08 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.76e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1000000.0\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 2439     |\n",
      "|    iterations           | 11       |\n",
      "|    time_elapsed         | 9        |\n",
      "|    total_timesteps      | 22528    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -28.4    |\n",
      "|    explained_variance   | 0        |\n",
      "|    learning_rate        | 0.0001   |\n",
      "|    loss                 | 1.4e+14  |\n",
      "|    n_updates            | 100      |\n",
      "|    policy_gradient_loss | 2.6e-06  |\n",
      "|    std                  | 1        |\n",
      "|    value_loss           | 2.79e+14 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1000000.0\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 2424      |\n",
      "|    iterations           | 12        |\n",
      "|    time_elapsed         | 10        |\n",
      "|    total_timesteps      | 24576     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 3.58e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.35e+14  |\n",
      "|    n_updates            | 110       |\n",
      "|    policy_gradient_loss | -2.19e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.76e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 2427      |\n",
      "|    iterations           | 13        |\n",
      "|    time_elapsed         | 10        |\n",
      "|    total_timesteps      | 26624     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.39e+14  |\n",
      "|    n_updates            | 120       |\n",
      "|    policy_gradient_loss | -3.43e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.76e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1000000.0\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 2415     |\n",
      "|    iterations           | 14       |\n",
      "|    time_elapsed         | 11       |\n",
      "|    total_timesteps      | 28672    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -28.4    |\n",
      "|    explained_variance   | 2.38e-07 |\n",
      "|    learning_rate        | 0.0001   |\n",
      "|    loss                 | 1.39e+14 |\n",
      "|    n_updates            | 130      |\n",
      "|    policy_gradient_loss | 2.26e-06 |\n",
      "|    std                  | 1        |\n",
      "|    value_loss           | 2.79e+14 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1000000.0\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 2404      |\n",
      "|    iterations           | 15        |\n",
      "|    time_elapsed         | 12        |\n",
      "|    total_timesteps      | 30720     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.38e+14  |\n",
      "|    n_updates            | 140       |\n",
      "|    policy_gradient_loss | -8.68e-08 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.76e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 2405      |\n",
      "|    iterations           | 16        |\n",
      "|    time_elapsed         | 13        |\n",
      "|    total_timesteps      | 32768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.36e+14  |\n",
      "|    n_updates            | 150       |\n",
      "|    policy_gradient_loss | -4.41e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.76e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1000000.0\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 2381     |\n",
      "|    iterations           | 17       |\n",
      "|    time_elapsed         | 14       |\n",
      "|    total_timesteps      | 34816    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -28.4    |\n",
      "|    explained_variance   | 0        |\n",
      "|    learning_rate        | 0.0001   |\n",
      "|    loss                 | 1.4e+14  |\n",
      "|    n_updates            | 160      |\n",
      "|    policy_gradient_loss | 2.18e-06 |\n",
      "|    std                  | 1        |\n",
      "|    value_loss           | 2.79e+14 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1000000.0\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 2373      |\n",
      "|    iterations           | 18        |\n",
      "|    time_elapsed         | 15        |\n",
      "|    total_timesteps      | 36864     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.38e+14  |\n",
      "|    n_updates            | 170       |\n",
      "|    policy_gradient_loss | -3.75e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.76e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1000000.0\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 2368      |\n",
      "|    iterations           | 19        |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 38912     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.38e+14  |\n",
      "|    n_updates            | 180       |\n",
      "|    policy_gradient_loss | -6.58e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.76e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 2384      |\n",
      "|    iterations           | 20        |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 40960     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.37e+14  |\n",
      "|    n_updates            | 190       |\n",
      "|    policy_gradient_loss | -4.11e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.76e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1000000.0\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 2378      |\n",
      "|    iterations           | 21        |\n",
      "|    time_elapsed         | 18        |\n",
      "|    total_timesteps      | 43008     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.39e+14  |\n",
      "|    n_updates            | 200       |\n",
      "|    policy_gradient_loss | -1.93e-06 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.79e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1000000.0\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 2373     |\n",
      "|    iterations           | 22       |\n",
      "|    time_elapsed         | 18       |\n",
      "|    total_timesteps      | 45056    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -28.4    |\n",
      "|    explained_variance   | 5.96e-08 |\n",
      "|    learning_rate        | 0.0001   |\n",
      "|    loss                 | 1.38e+14 |\n",
      "|    n_updates            | 210      |\n",
      "|    policy_gradient_loss | -8.8e-07 |\n",
      "|    std                  | 1        |\n",
      "|    value_loss           | 2.76e+14 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 2385      |\n",
      "|    iterations           | 23        |\n",
      "|    time_elapsed         | 19        |\n",
      "|    total_timesteps      | 47104     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.37e+14  |\n",
      "|    n_updates            | 220       |\n",
      "|    policy_gradient_loss | -2.66e-07 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.76e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1000000.0\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 2379      |\n",
      "|    iterations           | 24        |\n",
      "|    time_elapsed         | 20        |\n",
      "|    total_timesteps      | 49152     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.4e+14   |\n",
      "|    n_updates            | 230       |\n",
      "|    policy_gradient_loss | -1.05e-06 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.79e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1000000.0\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 2373      |\n",
      "|    iterations           | 25        |\n",
      "|    time_elapsed         | 21        |\n",
      "|    total_timesteps      | 51200     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -28.4     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.38e+14  |\n",
      "|    n_updates            | 240       |\n",
      "|    policy_gradient_loss | -4.3e-07  |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.76e+14  |\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.4.3 Model 3: DDPG : Deep Deterministic Policy Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ojmppgo4LPLz",
    "outputId": "bb2459a2-3231-481e-9628-4ace4256f9e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgents(env = env_train)\n",
    "DDPG_PARAMS = {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.001}\n",
    "\n",
    "\n",
    "model_ddpg = agent.get_model(\"ddpg\",model_kwargs = DDPG_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bWt6BIR0LT25",
    "outputId": "d523d157-f2c7-4667-9971-214ddc51fcb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to tensorboard_log/ddpg/ddpg_4\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1000000.0\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1000000.0\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1000000.0\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1000000.0\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 182       |\n",
      "|    time_elapsed    | 65        |\n",
      "|    total_timesteps | 11940     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -4.32e+07 |\n",
      "|    critic_loss     | 2.4e+09   |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 11839     |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1000000.0\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1000000.0\n",
      "=================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trained_ddpg \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_ddpg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mddpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Capstone Options/Capstone-Indian data/train_models.py:117\u001b[0m, in \u001b[0;36mDRLAgents.train_model\u001b[0;34m(self, model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, tb_log_name, total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m):\n\u001b[0;32m--> 117\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stable_baselines3/ddpg/ddpg.py:123\u001b[0m, in \u001b[0;36mDDPG.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfDDPG,\n\u001b[1;32m    116\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    121\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    122\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfDDPG:\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stable_baselines3/td3/td3.py:222\u001b[0m, in \u001b[0;36mTD3.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfTD3,\n\u001b[1;32m    215\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    220\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    221\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfTD3:\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stable_baselines3/common/off_policy_algorithm.py:347\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[38;5;66;03m# Special case when the user passes `gradient_steps=0`\u001b[39;00m\n\u001b[1;32m    346\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m gradient_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 347\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stable_baselines3/td3/td3.py:188\u001b[0m, in \u001b[0;36mTD3.train\u001b[0;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# Optimize the critics\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 188\u001b[0m \u001b[43mcritic_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# Delayed policy updates\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.4.4 Model 4: SAC : Soft Actor-Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.0003, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgents(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 100000,\n",
    "    \"learning_rate\": 0.0003,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to tensorboard_log/sac/sac_3\n"
     ]
    }
   ],
   "source": [
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.4.5 Model 5: TD3 : Twin Delayed Deep Deterministic Policy Gradien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgents(env = env_train)\n",
    "TD3_PARAMS = {\"batch_size\": 100, \n",
    "              \"buffer_size\": 1000000, \n",
    "              \"learning_rate\": 0.001}\n",
    "\n",
    "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to tensorboard_log/td3/td3_3\n"
     ]
    }
   ],
   "source": [
    "trained_td3 = agent.train_model(model=model_td3, \n",
    "                             tb_log_name='td3',\n",
    "                             total_timesteps=30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 Fittng Model on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# A2C Train Model\n",
    "e_trade_gym = StockPortfolioEnv(df = train_df, **env_kwargs)\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
    "\n",
    "a2c_train_daily_return, a2c_train_weights = DRLAgents.DRL_prediction(model=trained_a2c,\n",
    "                        test_data = train_df,\n",
    "                        test_env = env_trade,\n",
    "                        test_obs = obs_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# PPO Train Model\n",
    "e_trade_gym = StockPortfolioEnv(df = train_df, **env_kwargs)\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
    "\n",
    "ppo_train_daily_return, ppo_train_weights = DRLAgents.DRL_prediction(model=trained_ppo,\n",
    "                        test_data = train_df,\n",
    "                        test_env = env_trade,\n",
    "                        test_obs = obs_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# DDPG Train Model\n",
    "e_trade_gym = StockPortfolioEnv(df = train_df, **env_kwargs)\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
    "\n",
    "ddpg_train_daily_return, ddpg_train_weights = DRLAgents.DRL_prediction(model=trained_ddpg,\n",
    "                        test_data = train_df,\n",
    "                        test_env = env_trade,\n",
    "                        test_obs = obs_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# SAC Train Model\n",
    "e_trade_gym = StockPortfolioEnv(df = train_df, **env_kwargs)\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
    "\n",
    "sac_train_daily_return, sac_train_weights = DRLAgents.DRL_prediction(model=trained_sac,\n",
    "                        test_data = train_df,\n",
    "                        test_env = env_trade,\n",
    "                        test_obs = obs_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# TD3 Train Model\n",
    "e_trade_gym = StockPortfolioEnv(df = train_df, **env_kwargs)\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
    "\n",
    "td3_train_daily_return, td3_train_weights = DRLAgents.DRL_prediction(model=trained_td3,\n",
    "                        test_data = train_df,\n",
    "                        test_env = env_trade,\n",
    "                        test_obs = obs_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'a2c_train_daily_return' (DataFrame)\n",
      "Stored 'ppo_train_daily_return' (DataFrame)\n",
      "Stored 'ddpg_train_daily_return' (DataFrame)\n",
      "Stored 'sac_train_daily_return' (DataFrame)\n",
      "Stored 'td3_train_daily_return' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "# Store the Training Models\n",
    "%store a2c_train_daily_return\n",
    "%store ppo_train_daily_return\n",
    "%store ddpg_train_daily_return\n",
    "%store sac_train_daily_return\n",
    "%store td3_train_daily_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2Ma6YpTlnuZ"
   },
   "source": [
    "### 8.6 Trading\n",
    "Assume that we have $1,000,000 initial capital at 2024-01-01. We use the DDPG model to trade Dow jones 30 stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uas8U6k455sI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>cov_list</th>\n",
       "      <th>f01</th>\n",
       "      <th>f02</th>\n",
       "      <th>f03</th>\n",
       "      <th>f04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>2024-02-27</td>\n",
       "      <td>SUNPHARMA.NS</td>\n",
       "      <td>1585.449951</td>\n",
       "      <td>1549.050049</td>\n",
       "      <td>1582.750000</td>\n",
       "      <td>1556.750000</td>\n",
       "      <td>2140963</td>\n",
       "      <td>[[9.860392541309073e-05, -1.08803881131486e-05...</td>\n",
       "      <td>1.158366</td>\n",
       "      <td>1.36625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.018352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>2024-02-27</td>\n",
       "      <td>TATACHEM.NS</td>\n",
       "      <td>975.000000</td>\n",
       "      <td>958.750000</td>\n",
       "      <td>961.799988</td>\n",
       "      <td>972.000000</td>\n",
       "      <td>427306</td>\n",
       "      <td>[[9.860392541309073e-05, -1.08803881131486e-05...</td>\n",
       "      <td>1.158366</td>\n",
       "      <td>1.36625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.018352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>2024-02-27</td>\n",
       "      <td>TCS.NS</td>\n",
       "      <td>4124.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>4104.399902</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>2960475</td>\n",
       "      <td>[[9.860392541309073e-05, -1.08803881131486e-05...</td>\n",
       "      <td>1.158366</td>\n",
       "      <td>1.36625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.018352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>2024-02-27</td>\n",
       "      <td>ULTRACEMCO.NS</td>\n",
       "      <td>10151.000000</td>\n",
       "      <td>9881.450195</td>\n",
       "      <td>9951.099609</td>\n",
       "      <td>9930.049805</td>\n",
       "      <td>214186</td>\n",
       "      <td>[[9.860392541309073e-05, -1.08803881131486e-05...</td>\n",
       "      <td>1.158366</td>\n",
       "      <td>1.36625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.018352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>2024-02-27</td>\n",
       "      <td>WIPRO.NS</td>\n",
       "      <td>537.400024</td>\n",
       "      <td>527.549988</td>\n",
       "      <td>531.450012</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>5199630</td>\n",
       "      <td>[[9.860392541309073e-05, -1.08803881131486e-05...</td>\n",
       "      <td>1.158366</td>\n",
       "      <td>1.36625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.018352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date            tic         close         high          low  \\\n",
       "744  2024-02-27   SUNPHARMA.NS   1585.449951  1549.050049  1582.750000   \n",
       "744  2024-02-27    TATACHEM.NS    975.000000   958.750000   961.799988   \n",
       "744  2024-02-27         TCS.NS   4124.000000  3999.000000  4104.399902   \n",
       "744  2024-02-27  ULTRACEMCO.NS  10151.000000  9881.450195  9951.099609   \n",
       "744  2024-02-27       WIPRO.NS    537.400024   527.549988   531.450012   \n",
       "\n",
       "            open   volume                                           cov_list  \\\n",
       "744  1556.750000  2140963  [[9.860392541309073e-05, -1.08803881131486e-05...   \n",
       "744   972.000000   427306  [[9.860392541309073e-05, -1.08803881131486e-05...   \n",
       "744  3999.000000  2960475  [[9.860392541309073e-05, -1.08803881131486e-05...   \n",
       "744  9930.049805   214186  [[9.860392541309073e-05, -1.08803881131486e-05...   \n",
       "744   534.000000  5199630  [[9.860392541309073e-05, -1.08803881131486e-05...   \n",
       "\n",
       "          f01      f02  f03       f04  \n",
       "744  1.158366  1.36625  0.0  4.018352  \n",
       "744  1.158366  1.36625  0.0  4.018352  \n",
       "744  1.158366  1.36625  0.0  4.018352  \n",
       "744  1.158366  1.36625  0.0  4.018352  \n",
       "744  1.158366  1.36625  0.0  4.018352  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qq4W9FbSstT7",
    "outputId": "d92eb564-0231-45e9-cd3e-44b618537786"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# A2C Test Model\n",
    "e_trade_gym = StockPortfolioEnv(df = test_df, **env_kwargs)\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
    "\n",
    "a2c_test_daily_return, a2c_test_weights = DRLAgents.DRL_prediction(model=trained_a2c,\n",
    "                        test_data = test_df,\n",
    "                        test_env = env_trade,\n",
    "                        test_obs = obs_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "uJvj3pXt_Ukg",
    "outputId": "106b2f89-525c-4597-aa49-2a6739a612fe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  daily_return\n",
       "0  2021-02-23           0.0\n",
       "1  2021-02-23           0.0\n",
       "2  2021-02-23           0.0\n",
       "3  2021-02-23           0.0\n",
       "4  2021-02-23           0.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2c_test_daily_return.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xBX3Y68o1vRG"
   },
   "outputs": [],
   "source": [
    "a2c_test_weights.to_csv('a2c_test_weights.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASIANPAINT.NS</th>\n",
       "      <th>CIPLA.NS</th>\n",
       "      <th>DRREDDY.NS</th>\n",
       "      <th>GAIL.NS</th>\n",
       "      <th>GRASIM.NS</th>\n",
       "      <th>HDFCBANK.NS</th>\n",
       "      <th>HEROMOTOCO.NS</th>\n",
       "      <th>HINDUNILVR.NS</th>\n",
       "      <th>INFY.NS</th>\n",
       "      <th>ITC.NS</th>\n",
       "      <th>LT.NS</th>\n",
       "      <th>M&amp;M.NS</th>\n",
       "      <th>MARUTI.NS</th>\n",
       "      <th>NTPC.NS</th>\n",
       "      <th>POWERGRID.NS</th>\n",
       "      <th>SUNPHARMA.NS</th>\n",
       "      <th>TATACHEM.NS</th>\n",
       "      <th>TCS.NS</th>\n",
       "      <th>ULTRACEMCO.NS</th>\n",
       "      <th>WIPRO.NS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-23</th>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-23</th>\n",
       "      <td>0.027919</td>\n",
       "      <td>0.027919</td>\n",
       "      <td>0.052119</td>\n",
       "      <td>0.027919</td>\n",
       "      <td>0.075892</td>\n",
       "      <td>0.067281</td>\n",
       "      <td>0.048798</td>\n",
       "      <td>0.075892</td>\n",
       "      <td>0.027919</td>\n",
       "      <td>0.075892</td>\n",
       "      <td>0.028771</td>\n",
       "      <td>0.041693</td>\n",
       "      <td>0.027919</td>\n",
       "      <td>0.075892</td>\n",
       "      <td>0.033142</td>\n",
       "      <td>0.027919</td>\n",
       "      <td>0.075892</td>\n",
       "      <td>0.074999</td>\n",
       "      <td>0.075892</td>\n",
       "      <td>0.030332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-23</th>\n",
       "      <td>0.024985</td>\n",
       "      <td>0.024985</td>\n",
       "      <td>0.067917</td>\n",
       "      <td>0.067917</td>\n",
       "      <td>0.067917</td>\n",
       "      <td>0.030266</td>\n",
       "      <td>0.065212</td>\n",
       "      <td>0.062506</td>\n",
       "      <td>0.025282</td>\n",
       "      <td>0.067917</td>\n",
       "      <td>0.067917</td>\n",
       "      <td>0.067917</td>\n",
       "      <td>0.024985</td>\n",
       "      <td>0.067917</td>\n",
       "      <td>0.026439</td>\n",
       "      <td>0.024985</td>\n",
       "      <td>0.054113</td>\n",
       "      <td>0.067917</td>\n",
       "      <td>0.067917</td>\n",
       "      <td>0.024985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-23</th>\n",
       "      <td>0.027938</td>\n",
       "      <td>0.027938</td>\n",
       "      <td>0.028315</td>\n",
       "      <td>0.075943</td>\n",
       "      <td>0.075943</td>\n",
       "      <td>0.027938</td>\n",
       "      <td>0.027938</td>\n",
       "      <td>0.027938</td>\n",
       "      <td>0.027938</td>\n",
       "      <td>0.034865</td>\n",
       "      <td>0.075943</td>\n",
       "      <td>0.075943</td>\n",
       "      <td>0.075943</td>\n",
       "      <td>0.029832</td>\n",
       "      <td>0.075943</td>\n",
       "      <td>0.027938</td>\n",
       "      <td>0.075943</td>\n",
       "      <td>0.075943</td>\n",
       "      <td>0.075943</td>\n",
       "      <td>0.027938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-23</th>\n",
       "      <td>0.028909</td>\n",
       "      <td>0.060095</td>\n",
       "      <td>0.078584</td>\n",
       "      <td>0.067483</td>\n",
       "      <td>0.077145</td>\n",
       "      <td>0.028909</td>\n",
       "      <td>0.028909</td>\n",
       "      <td>0.078584</td>\n",
       "      <td>0.039706</td>\n",
       "      <td>0.028909</td>\n",
       "      <td>0.072342</td>\n",
       "      <td>0.028909</td>\n",
       "      <td>0.037682</td>\n",
       "      <td>0.058924</td>\n",
       "      <td>0.035741</td>\n",
       "      <td>0.028909</td>\n",
       "      <td>0.034183</td>\n",
       "      <td>0.078584</td>\n",
       "      <td>0.078584</td>\n",
       "      <td>0.028909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ASIANPAINT.NS  CIPLA.NS  DRREDDY.NS   GAIL.NS  GRASIM.NS  \\\n",
       "date                                                                   \n",
       "2021-02-23       0.050000  0.050000    0.050000  0.050000   0.050000   \n",
       "2021-02-23       0.027919  0.027919    0.052119  0.027919   0.075892   \n",
       "2021-02-23       0.024985  0.024985    0.067917  0.067917   0.067917   \n",
       "2021-02-23       0.027938  0.027938    0.028315  0.075943   0.075943   \n",
       "2021-02-23       0.028909  0.060095    0.078584  0.067483   0.077145   \n",
       "\n",
       "            HDFCBANK.NS  HEROMOTOCO.NS  HINDUNILVR.NS   INFY.NS    ITC.NS  \\\n",
       "date                                                                        \n",
       "2021-02-23     0.050000       0.050000       0.050000  0.050000  0.050000   \n",
       "2021-02-23     0.067281       0.048798       0.075892  0.027919  0.075892   \n",
       "2021-02-23     0.030266       0.065212       0.062506  0.025282  0.067917   \n",
       "2021-02-23     0.027938       0.027938       0.027938  0.027938  0.034865   \n",
       "2021-02-23     0.028909       0.028909       0.078584  0.039706  0.028909   \n",
       "\n",
       "               LT.NS    M&M.NS  MARUTI.NS   NTPC.NS  POWERGRID.NS  \\\n",
       "date                                                                \n",
       "2021-02-23  0.050000  0.050000   0.050000  0.050000      0.050000   \n",
       "2021-02-23  0.028771  0.041693   0.027919  0.075892      0.033142   \n",
       "2021-02-23  0.067917  0.067917   0.024985  0.067917      0.026439   \n",
       "2021-02-23  0.075943  0.075943   0.075943  0.029832      0.075943   \n",
       "2021-02-23  0.072342  0.028909   0.037682  0.058924      0.035741   \n",
       "\n",
       "            SUNPHARMA.NS  TATACHEM.NS    TCS.NS  ULTRACEMCO.NS  WIPRO.NS  \n",
       "date                                                                      \n",
       "2021-02-23      0.050000     0.050000  0.050000       0.050000  0.050000  \n",
       "2021-02-23      0.027919     0.075892  0.074999       0.075892  0.030332  \n",
       "2021-02-23      0.024985     0.054113  0.067917       0.067917  0.024985  \n",
       "2021-02-23      0.027938     0.075943  0.075943       0.075943  0.027938  \n",
       "2021-02-23      0.028909     0.034183  0.078584       0.078584  0.028909  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2c_test_weights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# PPO Test Model\n",
    "e_trade_gym = StockPortfolioEnv(df = test_df, **env_kwargs)\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
    "\n",
    "ppo_test_daily_return, ppo_test_weights = DRLAgents.DRL_prediction(model=trained_ppo,\n",
    "                        test_data = test_df,\n",
    "                        test_env = env_trade,\n",
    "                        test_obs = obs_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_test_weights.to_csv('ppo_test_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# DDPG Test Model\n",
    "e_trade_gym = StockPortfolioEnv(df = test_df, **env_kwargs)\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
    "\n",
    "ddpg_test_daily_return, ddpg_test_weights = DRLAgents.DRL_prediction(model=trained_ddpg,\n",
    "                        test_data = test_df,\n",
    "                        test_env = env_trade,\n",
    "                        test_obs = obs_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_test_weights.to_csv('ddpg_test_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# SAC Test Model\n",
    "e_trade_gym = StockPortfolioEnv(df = test_df, **env_kwargs)\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
    "\n",
    "sac_test_daily_return, sac_test_weights = DRLAgents.DRL_prediction(model=trained_sac,\n",
    "                        test_data = test_df,\n",
    "                        test_env = env_trade,\n",
    "                        test_obs = obs_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sac_test_weights.to_csv('sac_test_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# TD3 Test Model\n",
    "e_trade_gym = StockPortfolioEnv(df = test_df, **env_kwargs)\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
    "\n",
    "td3_test_daily_return, td3_test_weights = DRLAgents.DRL_prediction(model=trained_sac,\n",
    "                        test_data = test_df,\n",
    "                        test_env = env_trade,\n",
    "                        test_obs = obs_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td3_test_weights.to_csv('td3_test_weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.7 Save the Portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-2DgsIW-fh0s"
   },
   "outputs": [],
   "source": [
    "a2c_test_portfolio = a2c_test_daily_return.copy()\n",
    "a2c_test_returns = a2c_test_daily_return.copy()\n",
    "\n",
    "ppo_test_portfolio = ppo_test_daily_return.copy()\n",
    "ppo_test_returns = ppo_test_daily_return.copy()\n",
    "\n",
    "ddpg_test_portfolio = ddpg_test_daily_return.copy()\n",
    "ddpg_test_returns = ddpg_test_daily_return.copy()\n",
    "\n",
    "sac_test_portfolio = sac_test_daily_return.copy()\n",
    "sac_test_returns = sac_test_daily_return.copy()\n",
    "\n",
    "td3_test_portfolio = td3_test_daily_return.copy()\n",
    "td3_test_returns = td3_test_daily_return.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'a2c_test_portfolio' (DataFrame)\n",
      "Stored 'a2c_test_returns' (DataFrame)\n",
      "Stored 'ppo_test_portfolio' (DataFrame)\n",
      "Stored 'ppo_test_returns' (DataFrame)\n",
      "Stored 'ddpg_test_portfolio' (DataFrame)\n",
      "Stored 'ddpg_test_returns' (DataFrame)\n",
      "Stored 'sac_test_portfolio' (DataFrame)\n",
      "Stored 'sac_test_returns' (DataFrame)\n",
      "Stored 'td3_test_portfolio' (DataFrame)\n",
      "Stored 'td3_test_returns' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store a2c_test_portfolio\n",
    "%store a2c_test_returns \n",
    "\n",
    "%store ppo_test_portfolio\n",
    "%store ppo_test_returns \n",
    "\n",
    "%store ddpg_test_portfolio\n",
    "%store ddpg_test_returns \n",
    "\n",
    "%store sac_test_portfolio\n",
    "%store sac_test_returns\n",
    "\n",
    "%store td3_test_portfolio\n",
    "%store td3_test_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "lvrqTro3lhAh",
    "a3Iuv554xYFH",
    "SPEXBcm-uBJo"
   ],
   "include_colab_link": true,
   "name": "FinRL_portfolio_allocation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
